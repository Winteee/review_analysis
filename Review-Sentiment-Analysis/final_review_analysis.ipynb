{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 参考代码：https://github.com/Winteee/KerasTest/blob/master/KerasLSTM.py\n",
    "# 这是代码的文字解释：http://spaces.ac.cn/index.php/archives/3414/comment-page-1\n",
    "\n",
    "import pandas as pd #导入Pandas\n",
    "import numpy as np #导入Numpy\n",
    "import jieba #导入结巴分词\n",
    "import jieba.analyse\n",
    " \n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————语料预处理：数据导入————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (1,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewdata的数据格式为： Index(['reviewbody', 'score1', 'score2', 'score3'], dtype='object') Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                9,\n",
      "            ...\n",
      "            29990, 29991, 29992, 29993, 29994, 29995, 29996, 29997, 29998,\n",
      "            29999],\n",
      "           dtype='int64', length=30000)\n",
      "——————————over——————————\n"
     ]
    }
   ],
   "source": [
    "print(\"————————语料预处理：数据导入————————\")\n",
    "reviewfile=pd.read_csv('review30000.csv') #读取训练语料完毕\n",
    "\n",
    "reviewdata = pd.DataFrame()\n",
    "reviewdata[\"reviewbody\"]= reviewfile[\"b.reviewbody\"]\n",
    "reviewdata[\"score1\"]= reviewfile[\"口味评分\"]\n",
    "reviewdata[\"score2\"]= reviewfile[\"环境评分\"]\n",
    "reviewdata[\"score3\"]= reviewfile[\"服务评分\"]\n",
    "reviewdata = reviewdata.dropna(axis=0,how='any') #去掉所有有缺失值的行\n",
    "print(\"reviewdata的数据格式为：\",reviewdata.columns,reviewdata.index)\n",
    "print(\"——————————over——————————\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutwords(review_data):\n",
    "    cw = lambda x: list(jieba.cut(x)) #定义分词函数\n",
    "    review_data['review_cut_words'] = review_data[\"reviewbody\"].apply(cw)\n",
    "    print(\"——————————分词结束——————————\")\n",
    "    return review_data\n",
    "\n",
    "def cleanwords(review_data):\n",
    "    delwordslist = \"，/,/。/的/！/～/、/（/）/ /./。/吧\".split(\"/\")\n",
    "    if \"review_cut_words\" in review_data.columns:\n",
    "        for i in review_data.index:\n",
    "            one = review_data.review_cut_words[i]\n",
    "            for k in one:\n",
    "                if k in delwordslist:\n",
    "                    one.remove(k)\n",
    "            i +=1\n",
    "        return review_data\n",
    "    \n",
    "    elif \"review_cut_words\" not in review_data.columns:\n",
    "        print(\"cleanwords运行出错，请先运行cutwords函数以获取review_cut_words\")\n",
    "\n",
    "def countwords(review_data):\n",
    "    w = []\n",
    "    for i in review_data[\"review_cut_words\"]:\n",
    "        w.extend(i)\n",
    "    reviewdict = pd.DataFrame(pd.Series(w).value_counts(),columns = [\"counts\"])\n",
    "    print(\"——————————词频统计结束——————————\")\n",
    "    return reviewdict\n",
    "\n",
    "def arraywords(review_data,reviewdict):\n",
    "    reviewdict['id']=list(range(1,len(reviewdict)+1))\n",
    "    get_sent = lambda x: list(reviewdict[\"counts\"][x])\n",
    "    maxlen = 50\n",
    "    review_data['sent'] = review_data['review_cut_words'].apply(get_sent) \n",
    "    review_data['sent'] = list(sequence.pad_sequences(review_data['sent'], maxlen=maxlen))\n",
    "    print(\"——————————词向量化结束——————————\")\n",
    "    return review_data\n",
    "\n",
    "#def markwords(review_data):\n",
    " #   review_data[\"totalscore\"]= review_data.score1+review_data.score2+review_data.score3 \n",
    "  #  review_data[\"pos_or_neg\"] = pd.Series()\n",
    "    #print(review_data[:2])\n",
    "    #print(len(review_data.index))\n",
    "   # for i in range(len(review_data.index)):\n",
    "    #    if review_data[\"totalscore\"][i]>11:\n",
    "     #       review_data[\"pos_or_neg\"][i] = 1\n",
    "      #  elif review_data[\"totalscore\"][i]<4:\n",
    "       #     review_data[\"pos_or_neg\"][i] = 0\n",
    "        #i +=1\n",
    "    #print(\"——————————标注结束——————————\")\n",
    "    #return review_data\n",
    "\n",
    "\n",
    "def markwords(review_data):\n",
    "    review_data[\"totalscore\"]= review_data.score1+review_data.score2+review_data.score3 \n",
    "    review_data[\"pos_or_neg\"] = pd.Series()\n",
    "    pos = review_data[review_data.totalscore>11]\n",
    "    pos[\"pos_or_neg\"]=1\n",
    "    neg = review_data[review_data.totalscore<4]\n",
    "    neg[\"pos_or_neg\"] = 0\n",
    "    review_data = pos.append(neg)\n",
    "    print(\"——————————标注结束——————————\")\n",
    "    return review_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/t9/186m3wkn1c1c1y1m9dmv76zh0000gn/T/jieba.cache\n",
      "Loading model cost 5.214 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————分词结束——————————\n",
      "——————————词频统计结束——————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————词向量化结束——————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————标注结束——————————\n",
      "traindata information————————————————————————————————————————————————————\n",
      "                                          reviewbody  score1  score2  score3  \\\n",
      "4  去了好几次，德国猪肘是这里的特色菜，基本上每桌必点！还有这里的生啤也不错！如果要坐外面需要自...     4.0     4.0     4.0   \n",
      "6  以前去过几次衡山路那家 新天地这家是第一次来 新装修过的果然环境很不错 有种置身国外的感觉 ...     4.0     4.0     4.0   \n",
      "8                                  老饭店，味道一如既往好，价格实惠。     4.0     4.0     4.0   \n",
      "\n",
      "                                    review_cut_words  \\\n",
      "4  [去, 了, 好, 几次, 德国, 猪肘, 是, 这里, 特色菜, 基本上, 每桌, 必点,...   \n",
      "6  [以前, 去过, 几次, 衡山路, 那, 家, 新天地, 这家, 是, 第一次, 来, 新装...   \n",
      "8                       [老, 饭店, 味道, 一如既往, 好, 价格, 实惠]   \n",
      "\n",
      "                                                sent  totalscore  pos_or_neg  \n",
      "4  [4010, 21166, 8085, 325, 20, 8, 10337, 993, 46...        12.0           1  \n",
      "6  [164, 2382, 3708, 474, 3021, 20, 80, 604, 185,...        12.0           1  \n",
      "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        12.0           1   Index(['reviewbody', 'score1', 'score2', 'score3', 'review_cut_words', 'sent',\n",
      "       'totalscore', 'pos_or_neg'],\n",
      "      dtype='object') Int64Index([    4,     6,     8,    18,    19,    23,    24,    25,    28,\n",
      "               29,\n",
      "            ...\n",
      "            19784, 19787, 19790, 19792, 19801, 19848, 19876, 19902, 19957,\n",
      "            19964],\n",
      "           dtype='int64', length=9940)\n"
     ]
    }
   ],
   "source": [
    "a0 = reviewdata[0:25000]\n",
    "a1 = cutwords(a0)\n",
    "a2 = cleanwords(a1)\n",
    "reviewdict = countwords(a2)\n",
    "a4 = arraywords(a2,reviewdict) #a4.index:[reviewbody,score1,score2,score3,review_cut_words,sent]\n",
    "a5 = markwords(a4)\n",
    "traindata = a5\n",
    "traindata.to_csv(\"traindata.csv\",index=True,header=True)\n",
    "#predictdata = predict_data_input(reviewdata[20000:20100])\n",
    "print(\"traindata information————————————————————————————————————————————————————\")\n",
    "print(traindata[:3],traindata.columns,traindata.index)\n",
    "\n",
    "#print(\"predictdata information————————————————————————————————————————————————————\")\n",
    "#print(predictdata[:3],predictdata.columns,predictdata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    4,     6,     8,    18,    19,    23,    24,    25,    28,\n",
      "               29,\n",
      "            ...\n",
      "            19784, 19787, 19790, 19792, 19801, 19848, 19876, 19902, 19957,\n",
      "            19964],\n",
      "           dtype='int64', length=9940)\n",
      "————————模型构建中————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(units=32, recurrent_activation=\"hard_sigmoid\", activation=\"sigmoid\")`\n",
      "  del sys.path[0]\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=32, units=1)`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————模型构建完成————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4970 samples, validate on 4970 samples\n",
      "Epoch 1/5\n",
      "4970/4970 [==============================] - 88s 18ms/step - loss: 0.3047 - acc: 0.9103 - val_loss: 0.2249 - val_acc: 0.9189\n",
      "Epoch 2/5\n",
      "4970/4970 [==============================] - 82s 16ms/step - loss: 0.2162 - acc: 0.9209 - val_loss: 0.2001 - val_acc: 0.9211\n",
      "Epoch 3/5\n",
      "4970/4970 [==============================] - 82s 16ms/step - loss: 0.1875 - acc: 0.9247 - val_loss: 0.1857 - val_acc: 0.9296\n",
      "Epoch 4/5\n",
      "4970/4970 [==============================] - 77s 15ms/step - loss: 0.1551 - acc: 0.9398 - val_loss: 0.1751 - val_acc: 0.9314\n",
      "Epoch 5/5\n",
      "4970/4970 [==============================] - 60s 12ms/step - loss: 0.1406 - acc: 0.9503 - val_loss: 0.1779 - val_acc: 0.9412\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ..., \n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "4970/4970 [==============================] - 6s 1ms/step\n",
      "Test accuracy = : [0.17789492711754631, 0.94124748495742827]\n"
     ]
    }
   ],
   "source": [
    "traindata = traindata.dropna(axis=0,how='any') #去掉所有有缺失值的行\n",
    "\n",
    "print(traindata.index)\n",
    "x = np.array(list(traindata['sent']),dtype = object)[::2]  #x：训练数据的Numpy数组（如果模型有单个输入）或Numpy数组列表（如果模型有多个输入）。\n",
    "y = np.array(list(traindata['pos_or_neg']),dtype = object)[::2] #y：目标（标签）数据的Numpy数组（如果模型具有单个输出）或Numpy数组列表\n",
    "xt = np.array(list(traindata['sent']),dtype = object)[1::2] #测试集\n",
    "yt = np.array(list(traindata['pos_or_neg']),dtype = object)[1::2]\n",
    "xa = np.array(list(traindata['sent']),dtype = object) #全集\n",
    "ya = np.array(list(traindata['pos_or_neg']),dtype = object)\n",
    "\n",
    "print(\"————————模型构建中————————\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(reviewdict)+1, 256))\n",
    "model.add(LSTM(output_dim=32, activation='sigmoid', inner_activation='hard_sigmoid')) # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(input_dim = 32, output_dim = 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy']) #class_mode=\"binary\"\n",
    "print(\"————————模型构建完成————————\")\n",
    "model.fit(x, y, batch_size=32, nb_epoch=5, validation_data=(xt, yt),validation_steps=None) #训练时间为若干个小时\n",
    "\n",
    "classes = model.predict_classes(xa)\n",
    "print(classes)\n",
    "score = model.evaluate(xt, yt, verbose=1) #evaluate用来测试函数的性能\n",
    "print (\"Test accuracy = :\",score)\n",
    "#Keras文档使用三组不同的数据：培训数据，验证数据和测试数据。\n",
    "#(training data)训练数据用于优化模型参数。(validation data)验证数据用于对元参数进行选择，例如时期的数量。\n",
    "#在用最佳元参数优化模型之后，使用测试数据(test data)来获得对模型性能的合理估计。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————分词结束——————————\n",
      "——————————词频统计结束——————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————词向量化结束——————————\n",
      "200/200 [==============================] - 0s 1ms/step\n",
      "predict = : [[ 0.99459261]\n",
      " [ 0.97228348]\n",
      " [ 0.9882201 ]\n",
      " [ 0.68394518]\n",
      " [ 0.98563254]\n",
      " [ 0.99093318]\n",
      " [ 0.99524707]\n",
      " [ 0.99520761]\n",
      " [ 0.99592662]\n",
      " [ 0.99433631]\n",
      " [ 0.49383515]\n",
      " [ 0.24205263]\n",
      " [ 0.99514091]\n",
      " [ 0.65232325]\n",
      " [ 0.97910255]\n",
      " [ 0.94130331]\n",
      " [ 0.46000212]\n",
      " [ 0.99515659]\n",
      " [ 0.99588108]\n",
      " [ 0.66070002]\n",
      " [ 0.33103809]\n",
      " [ 0.98775792]\n",
      " [ 0.99583471]\n",
      " [ 0.99192643]\n",
      " [ 0.99480778]\n",
      " [ 0.99600655]\n",
      " [ 0.9834404 ]\n",
      " [ 0.21727842]\n",
      " [ 0.99563259]\n",
      " [ 0.99345857]\n",
      " [ 0.99469757]\n",
      " [ 0.99338865]\n",
      " [ 0.31810617]\n",
      " [ 0.99552488]\n",
      " [ 0.99583793]\n",
      " [ 0.99408215]\n",
      " [ 0.97873026]\n",
      " [ 0.99597126]\n",
      " [ 0.99318755]\n",
      " [ 0.99595428]\n",
      " [ 0.99384719]\n",
      " [ 0.99577576]\n",
      " [ 0.99593437]\n",
      " [ 0.51967037]\n",
      " [ 0.67530513]\n",
      " [ 0.74624693]\n",
      " [ 0.99135512]\n",
      " [ 0.99314946]\n",
      " [ 0.97241366]\n",
      " [ 0.99476659]\n",
      " [ 0.93151736]\n",
      " [ 0.98983395]\n",
      " [ 0.99572527]\n",
      " [ 0.99559778]\n",
      " [ 0.98989469]\n",
      " [ 0.9959566 ]\n",
      " [ 0.98959935]\n",
      " [ 0.80751157]\n",
      " [ 0.81555247]\n",
      " [ 0.97443753]\n",
      " [ 0.99062914]\n",
      " [ 0.40812421]\n",
      " [ 0.97069776]\n",
      " [ 0.94826645]\n",
      " [ 0.99516088]\n",
      " [ 0.989416  ]\n",
      " [ 0.99595803]\n",
      " [ 0.98313993]\n",
      " [ 0.97157031]\n",
      " [ 0.98178506]\n",
      " [ 0.99236274]\n",
      " [ 0.99460715]\n",
      " [ 0.72438395]\n",
      " [ 0.96830016]\n",
      " [ 0.98012859]\n",
      " [ 0.26920503]\n",
      " [ 0.98745906]\n",
      " [ 0.79757863]\n",
      " [ 0.91098452]\n",
      " [ 0.98071367]\n",
      " [ 0.99536276]\n",
      " [ 0.97581351]\n",
      " [ 0.90657485]\n",
      " [ 0.99478984]\n",
      " [ 0.98653388]\n",
      " [ 0.99551302]\n",
      " [ 0.85990947]\n",
      " [ 0.84483844]\n",
      " [ 0.99549061]\n",
      " [ 0.99369627]\n",
      " [ 0.98633665]\n",
      " [ 0.99600524]\n",
      " [ 0.97456872]\n",
      " [ 0.99600947]\n",
      " [ 0.99599743]\n",
      " [ 0.99585861]\n",
      " [ 0.99592716]\n",
      " [ 0.99580115]\n",
      " [ 0.99596196]\n",
      " [ 0.97548193]\n",
      " [ 0.92495149]\n",
      " [ 0.89160436]\n",
      " [ 0.99434102]\n",
      " [ 0.8651123 ]\n",
      " [ 0.98254931]\n",
      " [ 0.96964842]\n",
      " [ 0.98876697]\n",
      " [ 0.99195743]\n",
      " [ 0.99592954]\n",
      " [ 0.9954139 ]\n",
      " [ 0.9944548 ]\n",
      " [ 0.99389678]\n",
      " [ 0.99602449]\n",
      " [ 0.9802714 ]\n",
      " [ 0.99600703]\n",
      " [ 0.95223916]\n",
      " [ 0.92423964]\n",
      " [ 0.99601632]\n",
      " [ 0.99601644]\n",
      " [ 0.99560565]\n",
      " [ 0.9158988 ]\n",
      " [ 0.98637068]\n",
      " [ 0.99471599]\n",
      " [ 0.99595404]\n",
      " [ 0.97287434]\n",
      " [ 0.31832528]\n",
      " [ 0.99535584]\n",
      " [ 0.11180423]\n",
      " [ 0.99601173]\n",
      " [ 0.32180449]\n",
      " [ 0.99595994]\n",
      " [ 0.9888159 ]\n",
      " [ 0.83312821]\n",
      " [ 0.99577409]\n",
      " [ 0.99602318]\n",
      " [ 0.97672564]\n",
      " [ 0.26618075]\n",
      " [ 0.98812032]\n",
      " [ 0.99496955]\n",
      " [ 0.99585366]\n",
      " [ 0.98703903]\n",
      " [ 0.99464971]\n",
      " [ 0.99522156]\n",
      " [ 0.99600959]\n",
      " [ 0.99596643]\n",
      " [ 0.99578249]\n",
      " [ 0.97722322]\n",
      " [ 0.99601412]\n",
      " [ 0.99064296]\n",
      " [ 0.99599278]\n",
      " [ 0.99372512]\n",
      " [ 0.99600959]\n",
      " [ 0.99593604]\n",
      " [ 0.99569798]\n",
      " [ 0.99593109]\n",
      " [ 0.92242789]\n",
      " [ 0.95718747]\n",
      " [ 0.99600619]\n",
      " [ 0.99562329]\n",
      " [ 0.98685026]\n",
      " [ 0.99584442]\n",
      " [ 0.99577409]\n",
      " [ 0.9914192 ]\n",
      " [ 0.96172458]\n",
      " [ 0.80268329]\n",
      " [ 0.65041834]\n",
      " [ 0.39499536]\n",
      " [ 0.99460357]\n",
      " [ 0.99449903]\n",
      " [ 0.89084584]\n",
      " [ 0.92500883]\n",
      " [ 0.72998095]\n",
      " [ 0.9957028 ]\n",
      " [ 0.99485105]\n",
      " [ 0.9668296 ]\n",
      " [ 0.99600619]\n",
      " [ 0.9881683 ]\n",
      " [ 0.99591333]\n",
      " [ 0.99378282]\n",
      " [ 0.99529678]\n",
      " [ 0.93395084]\n",
      " [ 0.99597567]\n",
      " [ 0.8771295 ]\n",
      " [ 0.99374086]\n",
      " [ 0.95280278]\n",
      " [ 0.99539977]\n",
      " [ 0.97267973]\n",
      " [ 0.99389946]\n",
      " [ 0.99414957]\n",
      " [ 0.99496162]\n",
      " [ 0.99136508]\n",
      " [ 0.99568695]\n",
      " [ 0.99573576]\n",
      " [ 0.99596715]\n",
      " [ 0.81405383]\n",
      " [ 0.99116462]\n",
      " [ 0.99586594]\n",
      " [ 0.76522756]\n",
      " [ 0.95866752]\n",
      " [ 0.3417221 ]]\n",
      "predict type = : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b0 = reviewdata[25000:26000]\n",
    "b1 = cutwords(b0)\n",
    "b2 = cleanwords(b1)\n",
    "reviewdict_b = countwords(b2)\n",
    "b4 = arraywords(b2,reviewdict) #a4.index:[reviewbody,score1,score2,score3,review_cut_words,sent]\n",
    "predictdata = b4\n",
    "\n",
    "xb = np.array(list(predictdata['sent']),dtype = object)\n",
    "predict_result = model.predict(xb, batch_size=32, verbose=0)\n",
    "predict_classes_result = model.predict_classes(xb, batch_size=32, verbose=1)\n",
    "print(\"predict = :\",predict_result)\n",
    "print(\"predict type = :\",type(predict_result))\n",
    "p = predict_result.tolist()\n",
    "p2 = predict_classes_result.tolist()\n",
    "predict_data = pd.DataFrame()\n",
    "predict_data[\"prediction\"]= pd.Series()\n",
    "predict_data[\"prediction\"] = p\n",
    "predict_data[\"pre_classes\"] = p2\n",
    "predict_data[\"review_cut_words\"]=predictdata[\"review_cut_words\"]\n",
    "predict_data.to_csv(\"predict_data.csv\",index=True,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
