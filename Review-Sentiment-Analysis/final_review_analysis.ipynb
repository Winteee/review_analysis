{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 参考代码：https://github.com/Winteee/KerasTest/blob/master/KerasLSTM.py\n",
    "# 这是代码的文字解释：http://spaces.ac.cn/index.php/archives/3414/comment-page-1\n",
    "\n",
    "import pandas as pd #导入Pandas\n",
    "import numpy as np #导入Numpy\n",
    "import jieba #导入结巴分词\n",
    "import jieba.analyse\n",
    " \n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————语料预处理：数据导入————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (1,6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewdata的数据格式为： Index(['reviewbody', 'score1', 'score2', 'score3'], dtype='object') Int64Index([    0,     1,     2,     3,     4,     5,     6,     7,     8,\n",
      "                9,\n",
      "            ...\n",
      "            29990, 29991, 29992, 29993, 29994, 29995, 29996, 29997, 29998,\n",
      "            29999],\n",
      "           dtype='int64', length=30000)\n",
      "——————————over——————————\n"
     ]
    }
   ],
   "source": [
    "print(\"————————语料预处理：数据导入————————\")\n",
    "reviewfile=pd.read_csv('review30000.csv') #读取训练语料完毕\n",
    "\n",
    "reviewdata = pd.DataFrame()\n",
    "reviewdata[\"reviewbody\"]= reviewfile[\"b.reviewbody\"]\n",
    "reviewdata[\"score1\"]= reviewfile[\"口味评分\"]\n",
    "reviewdata[\"score2\"]= reviewfile[\"环境评分\"]\n",
    "reviewdata[\"score3\"]= reviewfile[\"服务评分\"]\n",
    "reviewdata = reviewdata.dropna(axis=0,how='any') #去掉所有有缺失值的行\n",
    "print(\"reviewdata的数据格式为：\",reviewdata.columns,reviewdata.index)\n",
    "print(\"——————————over——————————\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cutwords(review_data):\n",
    "    cw = lambda x: list(jieba.cut(x)) #定义分词函数\n",
    "    review_data['review_cut_words'] = review_data[\"reviewbody\"].apply(cw)\n",
    "    print(\"——————————分词结束——————————\")\n",
    "    return review_data\n",
    "\n",
    "def cleanwords(review_data):\n",
    "    delwordslist = \"，/,/。/的/！/～/、/（/）/ /./。/吧\".split(\"/\")\n",
    "    if \"review_cut_words\" in review_data.columns:\n",
    "        for i in review_data.index:\n",
    "            one = review_data.review_cut_words[i]\n",
    "            for k in one:\n",
    "                if k in delwordslist:\n",
    "                    one.remove(k)\n",
    "            i +=1\n",
    "        return review_data\n",
    "    \n",
    "    elif \"review_cut_words\" not in review_data.columns:\n",
    "        print(\"cleanwords运行出错，请先运行cutwords函数以获取review_cut_words\")\n",
    "\n",
    "def countwords(review_data):\n",
    "    w = []\n",
    "    for i in review_data[\"review_cut_words\"]:\n",
    "        w.extend(i)\n",
    "    reviewdict = pd.DataFrame(pd.Series(w).value_counts(),columns = [\"counts\"])\n",
    "    print(\"——————————词频统计结束——————————\")\n",
    "    return reviewdict\n",
    "\n",
    "def arraywords(review_data,reviewdict):\n",
    "    reviewdict['id']=list(range(1,len(reviewdict)+1))\n",
    "    get_sent = lambda x: list(reviewdict[\"counts\"][x])\n",
    "    maxlen = 50\n",
    "    review_data['sent'] = review_data['review_cut_words'].apply(get_sent) \n",
    "    review_data['sent'] = list(sequence.pad_sequences(review_data['sent'], maxlen=maxlen))\n",
    "    print(\"——————————词向量化结束——————————\")\n",
    "    return review_data\n",
    "\n",
    "#def markwords(review_data):\n",
    " #   review_data[\"totalscore\"]= review_data.score1+review_data.score2+review_data.score3 \n",
    "  #  review_data[\"pos_or_neg\"] = pd.Series()\n",
    "    #print(review_data[:2])\n",
    "    #print(len(review_data.index))\n",
    "   # for i in range(len(review_data.index)):\n",
    "    #    if review_data[\"totalscore\"][i]>11:\n",
    "     #       review_data[\"pos_or_neg\"][i] = 1\n",
    "      #  elif review_data[\"totalscore\"][i]<4:\n",
    "       #     review_data[\"pos_or_neg\"][i] = 0\n",
    "        #i +=1\n",
    "    #print(\"——————————标注结束——————————\")\n",
    "    #return review_data\n",
    "\n",
    "\n",
    "def markwords(review_data):\n",
    "    review_data[\"totalscore\"]= review_data.score1+review_data.score2+review_data.score3 \n",
    "    review_data[\"pos_or_neg\"] = pd.Series()\n",
    "    pos = review_data[review_data.totalscore>11]\n",
    "    pos[\"pos_or_neg\"]=1\n",
    "    neg = review_data[review_data.totalscore<4]\n",
    "    neg[\"pos_or_neg\"] = 0\n",
    "    review_data = pos.append(neg)\n",
    "    print(\"——————————标注结束——————————\")\n",
    "    return review_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_input(review_data):\n",
    "    a1 = cutwords(review_data)\n",
    "    a2 = cleanwords(a1)\n",
    "    a3 = countwords(a2)\n",
    "    a4 = arraywords(a2,a3) #a4.index:[reviewbody,score1,score2,score3,review_cut_words,sent]\n",
    "    a5 = markwords(a4)\n",
    "    return a5\n",
    "\n",
    "def predict_data_input(review_data):\n",
    "    a1 = cutwords(review_data)\n",
    "    a2 = cleanwords(a1)\n",
    "    a3 = countwords(a2)\n",
    "    a4 = arraywords(a2,a3) #a4.index:[reviewbody,score1,score2,score3,review_cut_words,sent]\n",
    "    return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/t9/186m3wkn1c1c1y1m9dmv76zh0000gn/T/jieba.cache\n",
      "Loading model cost 1.610 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————分词结束——————————\n",
      "——————————词频统计结束——————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————词向量化结束——————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————标注结束——————————\n",
      "traindata information————————————————————————————————————————————————————\n",
      "                                          reviewbody  score1  score2  score3  \\\n",
      "4  去了好几次，德国猪肘是这里的特色菜，基本上每桌必点！还有这里的生啤也不错！如果要坐外面需要自...     4.0     4.0     4.0   \n",
      "6  以前去过几次衡山路那家 新天地这家是第一次来 新装修过的果然环境很不错 有种置身国外的感觉 ...     4.0     4.0     4.0   \n",
      "8                                  老饭店，味道一如既往好，价格实惠。     4.0     4.0     4.0   \n",
      "\n",
      "                                    review_cut_words  \\\n",
      "4  [去, 了, 好, 几次, 德国, 猪肘, 是, 这里, 特色菜, 基本上, 每桌, 必点,...   \n",
      "6  [以前, 去过, 几次, 衡山路, 那, 家, 新天地, 这家, 是, 第一次, 来, 新装...   \n",
      "8                       [老, 饭店, 味道, 一如既往, 好, 价格, 实惠]   \n",
      "\n",
      "                                                sent  totalscore  pos_or_neg  \n",
      "4  [4010, 21166, 8085, 325, 20, 8, 10337, 993, 46...        12.0           1  \n",
      "6  [164, 2382, 3708, 474, 3021, 20, 80, 604, 185,...        12.0           1  \n",
      "8  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...        12.0           1   Index(['reviewbody', 'score1', 'score2', 'score3', 'review_cut_words', 'sent',\n",
      "       'totalscore', 'pos_or_neg'],\n",
      "      dtype='object') Int64Index([    4,     6,     8,    18,    19,    23,    24,    25,    28,\n",
      "               29,\n",
      "            ...\n",
      "            19784, 19787, 19790, 19792, 19801, 19848, 19876, 19902, 19957,\n",
      "            19964],\n",
      "           dtype='int64', length=9940)\n"
     ]
    }
   ],
   "source": [
    "a0 = reviewdata[0:20000]\n",
    "a1 = cutwords(a0)\n",
    "a2 = cleanwords(a1)\n",
    "reviewdict = countwords(a2)\n",
    "a4 = arraywords(a2,reviewdict) #a4.index:[reviewbody,score1,score2,score3,review_cut_words,sent]\n",
    "a5 = markwords(a4)\n",
    "traindata = a5\n",
    "traindata.to_csv(\"traindata.csv\",index=False,header=True)\n",
    "#predictdata = predict_data_input(reviewdata[20000:20100])\n",
    "print(\"traindata information————————————————————————————————————————————————————\")\n",
    "print(traindata[:3],traindata.columns,traindata.index)\n",
    "\n",
    "#print(\"predictdata information————————————————————————————————————————————————————\")\n",
    "#print(predictdata[:3],predictdata.columns,predictdata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([    4,     6,     8,    18,    19,    23,    24,    25,    28,\n",
      "               29,\n",
      "            ...\n",
      "            19784, 19787, 19790, 19792, 19801, 19848, 19876, 19902, 19957,\n",
      "            19964],\n",
      "           dtype='int64', length=9940)\n",
      "————————模型构建中————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(activation=\"sigmoid\", units=32, recurrent_activation=\"hard_sigmoid\")`\n",
      "  del sys.path[0]\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=32, units=1)`\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————模型构建完成————————\n",
      "Train on 4970 samples, validate on 4970 samples\n",
      "Epoch 1/5\n",
      "4970/4970 [==============================] - 56s 11ms/step - loss: 0.3830 - acc: 0.8463 - val_loss: 0.2498 - val_acc: 0.9189\n",
      "Epoch 2/5\n",
      "4970/4970 [==============================] - 48s 10ms/step - loss: 0.2408 - acc: 0.9203 - val_loss: 0.2069 - val_acc: 0.9201\n",
      "Epoch 3/5\n",
      "4970/4970 [==============================] - 45s 9ms/step - loss: 0.2042 - acc: 0.9229 - val_loss: 0.1965 - val_acc: 0.9213\n",
      "Epoch 4/5\n",
      "4970/4970 [==============================] - 45s 9ms/step - loss: 0.1805 - acc: 0.9266 - val_loss: 0.1901 - val_acc: 0.9274\n",
      "Epoch 5/5\n",
      "4970/4970 [==============================] - 53s 11ms/step - loss: 0.1557 - acc: 0.9394 - val_loss: 0.1796 - val_acc: 0.9324\n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ..., \n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "4970/4970 [==============================] - 7s 1ms/step\n",
      "Test accuracy = : [0.17958019513119633, 0.93239436620917604]\n"
     ]
    }
   ],
   "source": [
    "traindata = traindata.dropna(axis=0,how='any') #去掉所有有缺失值的行\n",
    "print(traindata.index)\n",
    "x = np.array(list(traindata['sent']),dtype = object)[::2]  #x：训练数据的Numpy数组（如果模型有单个输入）或Numpy数组列表（如果模型有多个输入）。\n",
    "y = np.array(list(traindata['pos_or_neg']),dtype = object)[::2] #y：目标（标签）数据的Numpy数组（如果模型具有单个输出）或Numpy数组列表\n",
    "xt = np.array(list(traindata['sent']),dtype = object)[1::2] #测试集\n",
    "yt = np.array(list(traindata['pos_or_neg']),dtype = object)[1::2]\n",
    "xa = np.array(list(traindata['sent']),dtype = object) #全集\n",
    "ya = np.array(list(traindata['pos_or_neg']),dtype = object)\n",
    "\n",
    "print(\"————————模型构建中————————\")\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(reviewdict)+1, 256))\n",
    "model.add(LSTM(output_dim=32, activation='sigmoid', inner_activation='hard_sigmoid')) # try using a GRU instead, for fun\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(input_dim = 32, output_dim = 1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy']) #class_mode=\"binary\"\n",
    "print(\"————————模型构建完成————————\")\n",
    "model.fit(x, y, batch_size=32, nb_epoch=5, validation_data=(xt, yt),validation_steps=None) #训练时间为若干个小时\n",
    "\n",
    "classes = model.predict_classes(xa)\n",
    "print(classes)\n",
    "score = model.evaluate(xt, yt, verbose=1) #evaluate用来测试函数的性能\n",
    "print (\"Test accuracy = :\",score)\n",
    "#Keras文档使用三组不同的数据：培训数据，验证数据和测试数据。\n",
    "#(training data)训练数据用于优化模型参数。(validation data)验证数据用于对元参数进行选择，例如时期的数量。\n",
    "#在用最佳元参数优化模型之后，使用测试数据(test data)来获得对模型性能的合理估计。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————分词结束——————————\n",
      "——————————词频统计结束——————————\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "——————————词向量化结束——————————\n",
      "predict = : [[ 0.99117285]\n",
      " [ 0.89488405]\n",
      " [ 0.95861006]\n",
      " ..., \n",
      " [ 0.9933688 ]\n",
      " [ 0.36331099]\n",
      " [ 0.98964137]]\n",
      "predict type = : <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "b0 = reviewdata[0:200]\n",
    "b1 = cutwords(a0)\n",
    "b2 = cleanwords(a1)\n",
    "reviewdict_b = countwords(a2)\n",
    "b4 = arraywords(a2,reviewdict_b) #a4.index:[reviewbody,score1,score2,score3,review_cut_words,sent]\n",
    "predictdata = b4\n",
    "\n",
    "xb = np.array(list(predictdata['sent']),dtype = object)\n",
    "predict_result = model.predict(xb, batch_size=32, verbose=0)\n",
    "print(\"predict = :\",predict_result)\n",
    "print(\"predict type = :\",type(predict_result))\n",
    "p = predict_result.tolist()\n",
    "predict_data = pd.DataFrame()\n",
    "predict_data[\"prediction\"]= pd.Series()\n",
    "predict_data[\"prediction\"] = p\n",
    "predict_data[\"review_cut_words\"]=predictdata[\"review_cut_words\"]\n",
    "predict_data.to_csv(\"predict_data.csv\",index=False,header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
